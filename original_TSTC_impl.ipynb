{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf73a34a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# train_tstc.py\n",
    "# TSTC (Triple-branch Swin Transformer with CBP and Deep Supervision) for disease + severity\n",
    "# Implements full five-term loss: l1 (disease), l2 (final severity from feat23), l3 (severity from feat13),\n",
    "# l4 (severity from feat2), l5 (severity from feat3), with a filtered AI-Challenger dataloader.\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Compact Bilinear Pooling (CBP)\n",
    "# ------------------------------\n",
    "\n",
    "class CompactBilinearPooling(nn.Module):\n",
    "    def __init__(self, input_dim1: int, input_dim2: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.register_buffer('h1', torch.randint(0, output_dim, (input_dim1,)))\n",
    "        self.register_buffer('s1', 2 * torch.randint(0, 2, (input_dim1,)) - 1)\n",
    "        self.register_buffer('h2', torch.randint(0, output_dim, (input_dim2,)))\n",
    "        self.register_buffer('s2', 2 * torch.randint(0, 2, (input_dim2,)) - 1)\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        fx1 = self._count_sketch(x1, self.h1, self.s1)\n",
    "        fx2 = self._count_sketch(x2, self.h2, self.s2)\n",
    "        cbp = torch.fft.ifft(torch.fft.fft(fx1) * torch.fft.fft(fx2)).real\n",
    "        cbp = torch.sign(cbp) * torch.sqrt(torch.clamp(cbp.abs(), min=1e-8))\n",
    "        cbp = F.normalize(cbp, p=2, dim=1)\n",
    "        cbp = cbp / (self.output_dim ** 0.5)  # scale by 1/sqrt(d)\n",
    "        return cbp\n",
    "\n",
    "    def _count_sketch(self, x: torch.Tensor, h: torch.Tensor, s: torch.Tensor) -> torch.Tensor:\n",
    "        h = h.to(x.device)\n",
    "        s = s.to(x.device)\n",
    "        h_batch = h.unsqueeze(0).repeat(x.size(0), 1)\n",
    "        s_batch = s.unsqueeze(0)\n",
    "        out = torch.zeros(x.size(0), self.output_dim, device=x.device)\n",
    "        out.scatter_add_(1, h_batch, x * s_batch)\n",
    "        return out\n",
    "\n",
    "# --------------\n",
    "# TSTC Backbone\n",
    "# --------------\n",
    "\n",
    "class TSTC(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_disease_classes: int,\n",
    "        num_severity_classes: int,\n",
    "        cbp_output_dim: int = 7680\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Swin-T backbone\n",
    "        swin = swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Shared stages (follow the provided notebook slicing of torchvision Swin blocks)\n",
    "        self.stage1 = swin.features[:2]\n",
    "        self.stage2 = swin.features[2:4]\n",
    "\n",
    "        # Split stages for the three branches\n",
    "        swin_stage3 = swin.features[4:6]\n",
    "        swin_stage4 = swin.features[6:8]\n",
    "\n",
    "        import copy\n",
    "        self.branch1_stage3 = copy.deepcopy(swin_stage3)  # disease\n",
    "        self.branch1_stage4 = copy.deepcopy(swin_stage4)\n",
    "\n",
    "        self.branch2_stage3 = copy.deepcopy(swin_stage3)  # severity\n",
    "        self.branch2_stage4 = copy.deepcopy(swin_stage4)\n",
    "\n",
    "        self.branch3_stage3 = copy.deepcopy(swin_stage3)  # deep supervision\n",
    "        self.branch3_stage4 = copy.deepcopy(swin_stage4)\n",
    "\n",
    "        feat_dim = 768  # Swin-T final stage embedding dim\n",
    "\n",
    "        # CBP fusions\n",
    "        self.cbp23 = CompactBilinearPooling(feat_dim, feat_dim, cbp_output_dim)   # for final severity\n",
    "        self.cbp13 = CompactBilinearPooling(feat_dim, feat_dim, cbp_output_dim)   # for deep supervision (feat1 x feat3)\n",
    "\n",
    "        # Heads:\n",
    "        # - disease final (feat1)\n",
    "        self.fc_disease = nn.Linear(feat_dim, num_disease_classes)\n",
    "        # - severity final (feat23)\n",
    "        self.fc_severity_final = nn.Linear(cbp_output_dim, num_severity_classes)\n",
    "        # - deep supervision severity heads\n",
    "        self.fc_sev_feat2 = nn.Linear(feat_dim, num_severity_classes)   # l4\n",
    "        self.fc_sev_feat3 = nn.Linear(feat_dim, num_severity_classes)   # l5\n",
    "        self.fc_sev_feat13 = nn.Linear(cbp_output_dim, num_severity_classes)  # l3\n",
    "\n",
    "    def _pool(self, feat_4d: torch.Tensor) -> torch.Tensor:\n",
    "        # Input: [B, H, W, C] from Swin features → pool to [B, C]\n",
    "        return F.adaptive_avg_pool2d(feat_4d.permute(0, 3, 1, 2), 1).flatten(1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        shared = self.stage2(self.stage1(x))\n",
    "\n",
    "        # Three branches\n",
    "        f1_4d = self.branch1_stage4(self.branch1_stage3(shared))\n",
    "        f2_4d = self.branch2_stage4(self.branch2_stage3(shared))\n",
    "        f3_4d = self.branch3_stage4(self.branch3_stage3(shared))\n",
    "\n",
    "        f1 = self._pool(f1_4d)   # disease-focused\n",
    "        f2 = self._pool(f2_4d)   # severity-focused\n",
    "        f3 = self._pool(f3_4d)   # deep-supervision-focused\n",
    "\n",
    "        # Fusions\n",
    "        f23 = self.cbp23(f2, f3)\n",
    "        f13 = self.cbp13(f1, f3)\n",
    "\n",
    "        # Outputs\n",
    "        disease_out = self.fc_disease(f1)              # l1\n",
    "        severity_final = self.fc_severity_final(f23)   # l2\n",
    "        sev_feat13 = self.fc_sev_feat13(f13)           # l3\n",
    "        sev_feat2 = self.fc_sev_feat2(f2)              # l4\n",
    "        sev_feat3 = self.fc_sev_feat3(f3)              # l5\n",
    "\n",
    "        if self.training:\n",
    "            return disease_out, severity_final, sev_feat13, sev_feat2, sev_feat3\n",
    "        else:\n",
    "            # Inference typically uses the final heads\n",
    "            return disease_out, severity_final\n",
    "\n",
    "def _compute_label_counts(train_ds):\n",
    "    # Count disease/severity occurrences using dataset’s mapping and samples\n",
    "    num_d = train_ds.num_disease_classes\n",
    "    num_s = train_ds.num_severity_classes\n",
    "    d_counts = torch.zeros(num_d, dtype=torch.long)\n",
    "    s_counts = torch.zeros(num_s, dtype=torch.long)\n",
    "    for _, numeric_label in train_ds.samples:\n",
    "        d = train_ds.label2disease[numeric_label]\n",
    "        s = train_ds.label2severity[numeric_label]\n",
    "        d_counts[d] += 1\n",
    "        s_counts[s] += 1\n",
    "    return d_counts, s_counts\n",
    "\n",
    "def _class_weights_from_counts(counts: torch.Tensor, scheme: str = \"effective\", beta: float = 0.999, max_w: float = 10.0):\n",
    "    counts = counts.float().clamp(min=1.0)\n",
    "    if scheme == \"effective\":\n",
    "        # Class-Balanced Loss (Cui et al.): w_c = (1 - β) / (1 - β^{n_c})\n",
    "        w = (1.0 - beta) / (1.0 - torch.pow(beta, counts))\n",
    "    else:\n",
    "        # Inverse frequency\n",
    "        w = 1.0 / counts\n",
    "    # Normalize to mean ≈ 1 and clip extremes\n",
    "    w = w * (w.numel() / w.sum().clamp(min=1e-8))\n",
    "    w = w.clamp(max=max_w)\n",
    "    return w\n",
    "# ------------\n",
    "# Five-term CE\n",
    "# ------------\n",
    "\n",
    "class TSTCLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        disease_weight: torch.Tensor | None = None,\n",
    "        severity_weight: torch.Tensor | None = None,\n",
    "        aux_lambda: float = 0.5,\n",
    "        print_every: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Register as buffers so they move with .to(device)\n",
    "        if disease_weight is not None:\n",
    "            self.register_buffer(\"w_disease\", disease_weight.float())\n",
    "        else:\n",
    "            self.w_disease = None\n",
    "        if severity_weight is not None:\n",
    "            self.register_buffer(\"w_severity\", severity_weight.float())\n",
    "        else:\n",
    "            self.w_severity = None\n",
    "\n",
    "        self.aux_lambda = float(aux_lambda)\n",
    "        self.print_every = int(print_every)\n",
    "        self._step = 0\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        disease_out, severity_final, sev_feat13, sev_feat2, sev_feat3 = outputs\n",
    "        disease_labels, severity_labels = targets\n",
    "\n",
    "        # Ensure weights live on the same device as logits\n",
    "        wd = self.w_disease.to(disease_out.device) if self.w_disease is not None else None\n",
    "        ws = self.w_severity.to(severity_final.device) if self.w_severity is not None else None\n",
    "\n",
    "        l1 = F.cross_entropy(disease_out, disease_labels, weight=wd)         # disease\n",
    "        l2 = F.cross_entropy(severity_final, severity_labels, weight=ws)     # final severity (feat23)\n",
    "        l3 = F.cross_entropy(sev_feat13, severity_labels, weight=ws)         # aux severity (feat13)\n",
    "        l4 = F.cross_entropy(sev_feat2, severity_labels, weight=ws)          # aux severity (feat2)\n",
    "        l5 = F.cross_entropy(sev_feat3, severity_labels, weight=ws)          # aux severity (feat3)\n",
    "\n",
    "        total = l1 + l2 + self.aux_lambda * (l3 + l4 + l5)\n",
    "\n",
    "        # Optional periodic logging\n",
    "        if self.print_every > 0 and (self._step % self.print_every == 0):\n",
    "            print(\n",
    "                f\"Losses => Disease: {l1.item():.4f}, \"\n",
    "                f\"Severity_final: {l2.item():.4f}, \"\n",
    "                f\"Sev_feat13: {l3.item():.4f}, \"\n",
    "                f\"Sev_feat2: {l4.item():.4f}, \"\n",
    "                f\"Sev_feat3: {l5.item():.4f}, \"\n",
    "                f\"Total: {total.item():.4f}\"\n",
    "            )\n",
    "        self._step += 1\n",
    "        return total\n",
    "# -------------------------------\n",
    "# AI-Challenger filtered dataset\n",
    "# -------------------------------\n",
    "\n",
    "# Keep only labels with severity information plus healthy\n",
    "SELECTED_LABEL_IDS = [\n",
    "    14,15, 39,40, 48,49, 52,53, 50,51,\n",
    "    34,35,44,45, 36,37,46,47, 10,11, 28,29,\n",
    "    7,8,42,43, 54,55, 22,23, 20,21, 12,13, 4,5,\n",
    "    56,57, 26,27, 2,3, 18,19,\n",
    "    # healthy labels\n",
    "    0,6,9,17,24,30,33,38,41\n",
    "]\n",
    "\n",
    "class AIChallengerSubset(Dataset):\n",
    "    def __init__(self, json_path: str, img_root: str, transform=None):\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(json_path, 'r') as f:\n",
    "            all_data = json.load(f)\n",
    "\n",
    "        # Filter samples\n",
    "        self.samples = [\n",
    "            (item[\"image_id\"], item[\"disease_class\"])\n",
    "            for item in all_data\n",
    "            if item[\"disease_class\"] in SELECTED_LABEL_IDS\n",
    "        ]\n",
    "\n",
    "        # Build maps: numeric label -> disease group index, severity index\n",
    "        self.label2disease, self.label2severity = self._build_label_maps()\n",
    "\n",
    "        # Derive class counts\n",
    "        self.num_disease_classes = len(set(self.label2disease.values()))\n",
    "        self.num_severity_classes = len(set(self.label2severity.values()))\n",
    "\n",
    "    def _build_label_maps(self) -> Tuple[Dict[int, int], Dict[int, int]]:\n",
    "        # 19 disease groups indexed from 1; healthy -> 0\n",
    "        disease_groups = [\n",
    "            [14,15], [39,40], [48,49], [52,53], [50,51],\n",
    "            [34,35,44,45], [36,37,46,47], [10,11], [28,29],\n",
    "            [7,8,42,43], [54,55], [22,23], [20,21],\n",
    "            [12,13], [4,5], [56,57], [26,27], [2,3], [18,19]\n",
    "        ]\n",
    "        label2disease, label2severity = {}, {}\n",
    "\n",
    "        # General (1) vs Serious (2) by even/odd parity in the provided mapping\n",
    "        for i, grp in enumerate(disease_groups, 1):\n",
    "            for label in grp:\n",
    "                label2disease[label] = i\n",
    "                label2severity[label] = 2 if (label % 2 == 1) else 1\n",
    "\n",
    "        # Healthy labels → disease 0, severity 0\n",
    "        for label in [0, 6, 9, 17, 24, 30, 33, 38, 41]:\n",
    "            label2disease[label] = 0\n",
    "            label2severity[label] = 0\n",
    "\n",
    "        return label2disease, label2severity\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_name, numeric_label = self.samples[idx]\n",
    "        img_path = os.path.join(self.img_root, img_name)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        disease_label = self.label2disease[numeric_label]\n",
    "        severity_label = self.label2severity[numeric_label]\n",
    "        return image, disease_label, severity_label\n",
    "\n",
    "# ------------------\n",
    "# Training utilities\n",
    "# ------------------\n",
    "\n",
    "def get_loaders(\n",
    "    train_json: str,\n",
    "    train_images: str,\n",
    "    val_json: str,\n",
    "    val_images: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4\n",
    "):\n",
    "    tf_train = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    tf_eval = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_ds = AIChallengerSubset(train_json, train_images, transform=tf_train)\n",
    "    val_ds = AIChallengerSubset(val_json, val_images, transform=tf_eval)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, train_ds, val_ds\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader: DataLoader, model: nn.Module, device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total, correct_d, correct_s = 0, 0, 0\n",
    "    for images, d_labels, s_labels in loader:\n",
    "        images = images.to(device)\n",
    "        d_labels = d_labels.to(device)\n",
    "        s_labels = s_labels.to(device)\n",
    "        d_logits, s_logits = model(images)\n",
    "        d_pred = d_logits.argmax(1)\n",
    "        s_pred = s_logits.argmax(1)\n",
    "        total += d_labels.size(0)\n",
    "        correct_d += (d_pred == d_labels).sum().item()\n",
    "        correct_s += (s_pred == s_labels).sum().item()\n",
    "    return 100.0 * correct_d / total, 100.0 * correct_s / total\n",
    "\n",
    "from tqdm.auto import tqdm  # add this import at top of your file\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(\n",
    "    train_json: str,\n",
    "    train_images: str,\n",
    "    val_json: str,\n",
    "    val_images: str,\n",
    "    epochs: int = 20,\n",
    "    batch_size: int = 32,\n",
    "    lr: float = 0.01,\n",
    "    momentum: float = 0.9,\n",
    "    weight_decay: float = 1e-4,\n",
    "    cbp_output_dim: int = 7680,\n",
    "    out_ckpt: str = \"tstc_best.pt\",\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    train_loader, val_loader, train_ds, _ = get_loaders(\n",
    "        train_json, train_images, val_json, val_images, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    num_disease = train_ds.num_disease_classes\n",
    "    num_severity = train_ds.num_severity_classes\n",
    "    print(f\"num_disease = {num_disease} || num_severity = {num_severity}\")\n",
    "\n",
    "    model = TSTC(num_disease, num_severity, cbp_output_dim=cbp_output_dim).to(device)\n",
    "    criterion = TSTCLoss()\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    best_val_score = -1.0\n",
    "\n",
    "    # Prepare checkpoint directory and track current-best file\n",
    "    ckpt_dir = os.path.dirname(out_ckpt) if os.path.dirname(out_ckpt) else \".\"\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    current_best_path = None\n",
    "\n",
    "    epoch_bar = tqdm(range(1, epochs + 1), desc=\"Epochs\", position=0)\n",
    "    for epoch in epoch_bar:\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        batch_bar = tqdm(\n",
    "            train_loader,\n",
    "            desc=f\"Train {epoch}/{epochs}\",\n",
    "            leave=False,\n",
    "            position=1,\n",
    "        )\n",
    "\n",
    "        for images, d_labels, s_labels in batch_bar:\n",
    "            images = images.to(device)\n",
    "            d_labels = d_labels.to(device)\n",
    "            s_labels = s_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # returns 5 heads in train mode\n",
    "            loss = criterion(outputs, (d_labels, s_labels))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            avg_loss = running / max(1, batch_bar.n)\n",
    "            batch_bar.set_postfix(loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "        train_d_acc, train_s_acc = evaluate(train_loader, model, device)\n",
    "        val_d_acc, val_s_acc = evaluate(val_loader, model, device)\n",
    "\n",
    "        epoch_bar.set_postfix(\n",
    "            loss=f\"{running/len(train_loader):.4f}\",\n",
    "            trainD=f\"{train_d_acc:.2f}%\",\n",
    "            trainS=f\"{train_s_acc:.2f}%\",\n",
    "            valD=f\"{val_d_acc:.2f}%\",\n",
    "            valS=f\"{val_s_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | loss={running/len(train_loader):.4f} \"\n",
    "            f\"| train D={train_d_acc:.2f}% S={train_s_acc:.2f}% \"\n",
    "            f\"| val D={val_d_acc:.2f}% S={val_s_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        combined = 0.5 * (val_d_acc + val_s_acc)\n",
    "        if combined > best_val_score:\n",
    "            best_val_score = combined\n",
    "\n",
    "            # Save to a temp path first to avoid partial writes\n",
    "            tmp_path = os.path.join(ckpt_dir, f\".tmp_epoch{epoch}.pt\")\n",
    "            payload = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"num_disease\": num_disease,\n",
    "                \"num_severity\": num_severity,\n",
    "                \"epoch\": epoch,\n",
    "                \"val_d_acc\": val_d_acc,\n",
    "                \"val_s_acc\": val_s_acc,\n",
    "                \"combined\": combined,\n",
    "            }\n",
    "            torch.save(payload, tmp_path)\n",
    "\n",
    "            # Remove previous best, if any\n",
    "            if current_best_path and os.path.exists(current_best_path):\n",
    "                try:\n",
    "                    os.remove(current_best_path)\n",
    "                except OSError:\n",
    "                    pass\n",
    "\n",
    "            # Atomically move tmp to final out_ckpt\n",
    "            try:\n",
    "                os.replace(tmp_path, out_ckpt)\n",
    "            except Exception:\n",
    "                # Fallback: copy then remove\n",
    "                import shutil\n",
    "                shutil.copyfile(tmp_path, out_ckpt)\n",
    "                os.remove(tmp_path)\n",
    "\n",
    "            current_best_path = out_ckpt\n",
    "            tqdm.write(f\"  -> Saved best checkpoint to {out_ckpt} (epoch {epoch}, combined={combined:.3f})\")\n",
    "\n",
    "\n",
    "# --- Validate dataset paths before proceeding ---\n",
    "import os, sys\n",
    "def verify_path(json_path, img_dir, name=\"train\"):\n",
    "    print(f\"\\n[Checking {name} dataset paths...]\")\n",
    "    if not os.path.isfile(json_path):\n",
    "        print(f\"❌ ERROR: The JSON file for {name} dataset was not found:\\n   → {json_path}\")\n",
    "        print(\"💡 Fix: Ensure TRAIN_JSON / VAL_JSON points to a valid file.\\n\")\n",
    "        sys.exit(1)\n",
    "    if not os.path.isdir(img_dir):\n",
    "        print(f\"❌ ERROR: The image directory for {name} dataset was not found:\\n   → {img_dir}\")\n",
    "        print(\"💡 Fix: Ensure TRAIN_IMG_DIR / VAL_IMG_DIR points to an existing folder containing images.\\n\")\n",
    "        sys.exit(1)\n",
    "    print(f\"✅ {name.capitalize()} dataset paths verified successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"starting\")\n",
    "    # TODO: set these paths to the AI-Challenger 2018 dataset locations\n",
    "    # Train/val split can be constructed by random split or using provided splits if available\n",
    "    TRAIN_JSON = \"/kaggle/input/ai-challenger-dataset/ai_challenger_pdr2018/train/train_label.json\"\n",
    "    TRAIN_IMG_DIR = \"/kaggle/input/ai-challenger-dataset/ai_challenger_pdr2018/train/images\"\n",
    "    VAL_JSON = \"/kaggle/input/ai-challenger-dataset/ai_challenger_pdr2018/test/test_label.json\" \n",
    "    VAL_IMG_DIR = \"/kaggle/input/ai-challenger-dataset/ai_challenger_pdr2018/test/images\"\n",
    "\n",
    "    # Minimal guard to prevent accidental run without paths\n",
    "    verify_path(TRAIN_JSON, TRAIN_IMG_DIR, \"train\")\n",
    "    verify_path(VAL_JSON, VAL_IMG_DIR, \"validation\")\n",
    "\n",
    "    train(\n",
    "        train_json=TRAIN_JSON,\n",
    "        train_images=TRAIN_IMG_DIR,\n",
    "        val_json=VAL_JSON,\n",
    "        val_images=VAL_IMG_DIR,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        lr=0.001,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-4,\n",
    "        cbp_output_dim=7680,\n",
    "        out_ckpt=\"tstc_best.pt\",\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
